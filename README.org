* pywik
Welcome to pywik the static webserver csv logfile analyzer.
** What you get
 - big csv-s split into monthly chunks
 - the date is converted to ISO format
 - the request is split into request_type, path and http_version fields
 - ispage indicating if the path is a page or a requisite element like .js or .css files.
 - isbot indicates if the useragent belongs to a crawler
 - hostname of remote_addr
 - unquoted referer
 - extref indicates if a referer is from an external page
 - search query from bing and google
 - country code from maxmind geoip
** Setup
   download & unzip into your pywik folder:
   http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz

   install the dependencies:
   #+BEGIN_SRC
   pip install numpy
   pip install -r deps.txt
   #+END_SRC

   enrich your csvs:
   #+BEGIN_SRC
   python splitcsv.py access.csv http://www.example.org https://www.example.org http://www2.example.org https://www2.example.org
   #+END_SRC
   where the urls signal site-internal referers
** Web-server logformat
   #+BEGIN_SRC
   set your webserver (nginx) to use these as logformats:
        log_format csv-http  '"$time_local";$connection;"$remote_addr";0;"$http_host";"$request";'
                '$status;$request_length;$body_bytes_sent;$request_time;"$http_referer";"$remote_user";'
                '"$http_user_agent";"$http_x_forwarded_for";$msec';
        log_format csv-https '"$time_local";$connection;"$remote_addr";1;"$http_host";"$request";'
                '$status;$request_length;$body_bytes_sent;$request_time;"$http_referer";"$remote_user";'
                '"$http_user_agent";"$http_x_forwarded_for";$msec';
   #+END_SRC
   and for your hosts use them for logging:
   #+BEGIN_SRC
    access_log /var/log/nginx/parltrack-access.csv csv-http;
   #+END_SRC
   or
   #+BEGIN_SRC
    access_log /var/log/nginx/parltrack-access.csv csv-https;
   #+END_SRC
   respectively for https hosts
